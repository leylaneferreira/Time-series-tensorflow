{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVFW4aRbcfBb"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gssW9ThEVrpU"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11hjDPOkdktU",
        "outputId": "d70f33f2-4729-40d8-b653-ac74fa5b2b64"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "# Asynchronous, needed for federated learning\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Tensorflow Keras\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import (InputLayer, Dense, Flatten, Conv1D, MaxPool1D, Dropout, Activation)\n",
        "\n",
        "# Others\n",
        "import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muDkY8giCYyd",
        "outputId": "ee99cb5c-d347-47cd-8b02-3b3cc88eab16"
      },
      "outputs": [],
      "source": [
        "def readAllDatasetsPaths(n_files_adl, n_files_fall):\n",
        "  paths_fall = {}\n",
        "  paths_adl = {}\n",
        "  i=1\n",
        "  for x in range (1, n_files_adl+1):\n",
        "    p = \"/Datasets/\"+str(x)+\".csv\"\n",
        "    paths_adl['client'+str(i)] = p\n",
        "    i+=1\n",
        "  for y in range(1, n_files_fall+1):\n",
        "    p = \"/Datasets/\"+str(y)+\".csv\"\n",
        "    paths_fall['client'+str(i)] = p\n",
        "    i+=1\n",
        "  return paths_adl, paths_fall\n",
        "\n",
        "paths_adl, paths_fall = readAllDatasetsPaths(10, 10)\n",
        "\n",
        "print(paths_adl)\n",
        "print(paths_fall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kc7YONZDdHng"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 8\n",
        "BATCH_SIZE = 16\n",
        "SHUFFLE_BUFFER = 360\n",
        "PREFETCH_BUFFER = 8\n",
        "client_instance = 360\n",
        "\n",
        "def load_client_ds(path_adl, path_fall, client_instance):\n",
        "\n",
        "    h_client_instance = int(client_instance/2)\n",
        "\n",
        "    #Defining one hot encode y\n",
        "    y_adl = np.full((h_client_instance, 2), [1, 0])\n",
        "    y_fall = np.full((h_client_instance, 2), [0, 1])\n",
        "    y = np.concatenate((y_adl, y_fall), axis=0)\n",
        "\n",
        "    #Reading datasets\n",
        "    df_adl = pd.read_csv(path_adl, header=None)\n",
        "    df_fall = pd.read_csv(path_fall, header=None)\n",
        "\n",
        "    # Getting only accelerometer columns (x,y,z)\n",
        "    X_adl = df_adl.iloc[:, :-1]\n",
        "    X_fall = df_fall.iloc[:, :-1]\n",
        "\n",
        "    #applying normalization\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    X_adl = scaler.fit_transform(X_adl)\n",
        "    X_fall = scaler.fit_transform(X_fall)\n",
        "\n",
        "    n1 = int(len(X_adl)/2)\n",
        "    n2 = int(len(X_fall)/2)\n",
        "\n",
        "    #Adding two classes a each dataset\n",
        "    X1 = np.concatenate((X_adl[0:n1], X_fall[0:n2]), axis=0)\n",
        "    X2 = np.concatenate((X_adl[n1:],  X_fall[n2:]), axis=0)\n",
        "\n",
        "    X1 = np.reshape(X1, (client_instance, 500, 3))\n",
        "    X2 = np.reshape(X2, (client_instance, 500, 3))\n",
        "\n",
        "    # create tensorflow dataset\n",
        "    dataset1 = tf.data.Dataset.from_tensor_slices((X1, y))\n",
        "    dataset2 = tf.data.Dataset.from_tensor_slices((X2, y))\n",
        "\n",
        "    dataset1 = dataset1.batch(BATCH_SIZE).repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).prefetch(PREFETCH_BUFFER)\n",
        "    dataset2 = dataset2.batch(BATCH_SIZE).repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "    return dataset1, dataset2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ok1UmCt-joCL"
      },
      "outputs": [],
      "source": [
        "def get_dataset_partitions(dataset_list, dataset_list_len, train_split=0.8, test_split=0.2, shuffle=True):\n",
        "\n",
        "  if shuffle:\n",
        "   random.shuffle(dataset_list)\n",
        "\n",
        "  n_train = int(dataset_list_len * train_split)\n",
        "\n",
        "  train_data = dataset_list[:n_train]\n",
        "  test_data = dataset_list[n_train:]\n",
        "\n",
        "  return train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HG4V7CNruPPi"
      },
      "outputs": [],
      "source": [
        "ds1, ds2 = map(list, zip(*[load_client_ds(paths_adl[x], paths_fall[y], client_instance) for (x, y) in zip(paths_adl, paths_fall)]))\n",
        "clients_ds = ds1 + ds2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMgbNs6lzkvc",
        "outputId": "af6a3997-4253-40ff-ada2-2ea9a6f99a98"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = get_dataset_partitions(clients_ds, len(clients_ds))\n",
        "tf.data.experimental.cardinality(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNUa8YveWspR"
      },
      "source": [
        "Creating Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NqvXnKmAgnjE"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(InputLayer(input_shape=(500, 3)))\n",
        "    n_classes = 2\n",
        "\n",
        "    model.add(tf.keras.layers.Conv1D(32, 3, padding='causal', activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.MaxPooling1D(2, strides=2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv1D(64, 3, padding='causal', activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.MaxPooling1D(2, strides=2))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Dense(n_classes, activation=\"softmax\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krAwq87D1oIB"
      },
      "source": [
        "**Creating FL model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M8UiJADapDNB"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec= train_data[0].element_spec,\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc'),\\\n",
        "               tf.keras.metrics.Precision(name='pr'),\\\n",
        "               tf.keras.metrics.Recall(name='rc')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05lrCeHTYnMq",
        "outputId": "17fab76a-efa3-4ef2-f10d-eb806df5bf5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 500, 32)           320       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 250, 32)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 250, 64)           6208      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 125, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8000)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               800100    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 806830 (3.08 MB)\n",
            "Trainable params: 806830 (3.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_keras_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOYHcUkgCm_b"
      },
      "source": [
        "Federated Learning setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsAvLbKI0zU_",
        "outputId": "44841a7d-ec3f-4249-a464-7ea5e37b9ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round     0, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('acc', 0.69134116), ('pr', 0.69134116), ('rc', 0.69134116), ('loss', 0.56044203), ('num_examples', 46080), ('num_batches', 2944)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round     1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('acc', 0.7019314), ('pr', 0.7019314), ('rc', 0.7019314), ('loss', 0.5501223), ('num_examples', 46080), ('num_batches', 2944)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round     2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('acc', 0.70360243), ('pr', 0.70360243), ('rc', 0.70360243), ('loss', 0.5433214), ('num_examples', 46080), ('num_batches', 2944)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round     3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('acc', 0.7129123), ('pr', 0.7129123), ('rc', 0.7129123), ('loss', 0.53820807), ('num_examples', 46080), ('num_batches', 2944)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round     4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('acc', 0.717513), ('pr', 0.717513), ('rc', 0.717513), ('loss', 0.52583045), ('num_examples', 46080), ('num_batches', 2944)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "NUM_ROUNDS = 5\n",
        "\n",
        "client_lr = 1e-2\n",
        "server_lr = 1e-2\n",
        "\n",
        "\n",
        "# Simulate federated learning with federated averaging as model aggregation\n",
        "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn= lambda: tf.keras.optimizers.SGD(client_lr),\n",
        "    server_optimizer_fn= lambda: tf.keras.optimizers.SGD(server_lr))\n",
        "\n",
        "# Init\n",
        "train_state = training_process.initialize()\n",
        "\n",
        "for i in range(NUM_ROUNDS):\n",
        "    result = training_process.next(train_state, train_data)\n",
        "    train_state = result.state\n",
        "    metrics = result.metrics\n",
        "    print('round {:5d}, metrics={}'.format(i, metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gepxFFTfsIP5"
      },
      "outputs": [],
      "source": [
        "evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)\n",
        "evaluation_state = evaluation_process.initialize() #item novo\n",
        "model_weights = training_process.get_model_weights(train_state)\n",
        "evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpuywO7p2qWt",
        "outputId": "ad5287d3-5473-4821-86fc-609d58c6648b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work',\n",
              "              OrderedDict([('eval',\n",
              "                            OrderedDict([('current_round_metrics',\n",
              "                                          OrderedDict([('acc', 0.5),\n",
              "                                                       ('pr', 0.5),\n",
              "                                                       ('rc', 0.5),\n",
              "                                                       ('loss', 0.67714024),\n",
              "                                                       ('num_examples', 46080),\n",
              "                                                       ('num_batches',\n",
              "                                                        2944)])),\n",
              "                                         ('total_rounds_metrics',\n",
              "                                          OrderedDict([('acc', 0.5),\n",
              "                                                       ('pr', 0.5),\n",
              "                                                       ('rc', 0.5),\n",
              "                                                       ('loss', 0.67714024),\n",
              "                                                       ('num_examples', 46080),\n",
              "                                                       ('num_batches',\n",
              "                                                        2944)]))]))])),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_output = evaluation_process.next(evaluation_state, train_data)\n",
        "training_output.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPaI5wDX2tQM",
        "outputId": "7708e918-fe93-427c-a964-a1c101c68977"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work',\n",
              "              OrderedDict([('eval',\n",
              "                            OrderedDict([('current_round_metrics',\n",
              "                                          OrderedDict([('acc', 0.5),\n",
              "                                                       ('pr', 0.5),\n",
              "                                                       ('rc', 0.5),\n",
              "                                                       ('loss', 0.6769778),\n",
              "                                                       ('num_examples', 11520),\n",
              "                                                       ('num_batches', 736)])),\n",
              "                                         ('total_rounds_metrics',\n",
              "                                          OrderedDict([('acc', 0.5),\n",
              "                                                       ('pr', 0.5),\n",
              "                                                       ('rc', 0.5),\n",
              "                                                       ('loss', 0.6769778),\n",
              "                                                       ('num_examples', 11520),\n",
              "                                                       ('num_batches',\n",
              "                                                        736)]))]))])),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', ())])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation_output = evaluation_process.next(evaluation_state, test_data)\n",
        "evaluation_output.metrics"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
